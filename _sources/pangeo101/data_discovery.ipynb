{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee67085-c7cb-42e0-893f-9ca7a176a16d",
   "metadata": {},
   "source": [
    "# Data access and discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b9ab8-508f-47f4-85dd-03cb034a8e19",
   "metadata": {},
   "source": [
    "## Authors & Contributors\n",
    "\n",
    "### Authors\n",
    "\n",
    "- Pier Lorenzo Marasco, Ispra (Italy), [@pl-marasco](https://github.com/pl-marasco)\n",
    "- Alejandro Coca-Castro, The Alan Turing Institute (United Kingdom), [@acocac](https://github.com/acocac)\n",
    "\n",
    "### Contributors\n",
    "- Tina Odaka, Ifremer (France), [@tinaok](https://github.com/tinaok)\n",
    "- Anne Fouilloux, University of Oslo (Norway), [@annefou](https://github.com/annefou)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c0486-d262-42b7-b711-45fddaa0bfbc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <i class=\"fa-question-circle fa\" style=\"font-size: 22px;color:#666;\"></i> <b>Overview</b>\n",
    "    <br>\n",
    "    <br>\n",
    "    <b>Questions</b>\n",
    "    <ul>\n",
    "        <li>How to access online (remote) datasets?</li>\n",
    "        <li>How to prepare and discover online geoscience datasets?</li>\n",
    "        <li>What is Analysis Ready, Cloud Optimized data (ARCO)?</li>\n",
    "        <li>What is pangeo-forge?</li>\n",
    "        <li>What is stac?</li>\n",
    "    </ul>\n",
    "    <b>Objectives</b>\n",
    "    <ul>\n",
    "        <li>Learn to access datasets from online object storage</li>\n",
    "        <li>Learn about preparing and discovery online datasets</li>\n",
    "        <li>Learn about Analysis Cloud Optimized (ARCO) data</li>\n",
    "        <li>Learn about the Pangeo Forge initiative</li>\n",
    "        <li>Learn about stac</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651606-d4ae-4833-8825-4dc66f2503e1",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "We will be using Long Term Statistics (1999-2019) product provided by the [Copernicus Global Land Service](https://land.copernicus.eu/global/index.html) over Lombardia and access them through [S3-compatible storage](https://en.wikipedia.org/wiki/Amazon_S3). We will also explore [Sentinel-2 Cloud-Optimised Dataset](https://registry.opendata.aws/sentinel-2-l2a-cogs/) online through SpatioTemporal Asset Catalogs ([STAC](https://stacspec.org/en))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c3071-fbb6-4419-abb5-3f8783284438",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This episode uses the following main Python packages:\n",
    "\n",
    "- xarray {cite:ps}`c-xarray-hoyer2017` with [`netCDF4`](https://pypi.org/project/h5netcdf/) and [`h5netcdf`](https://pypi.org/project/h5netcdf/) engines\n",
    "- s3fs {cite:ps}`c-s3fs-2016`\n",
    "\n",
    "Please install these packages if not already available in your Python environment.\n",
    "\n",
    "### Packages\n",
    "\n",
    "In this episode, Python packages are imported when we start to use them. However, for best software practices, we recommend you to install and import all the necessary libraries at the top of your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d976a91-0952-4247-9a1e-b52b850fdb7b",
   "metadata": {},
   "source": [
    "## Introduction to the Long Term statistics\n",
    "CGLS LTS are computed over a time span of 20 years aggregated over separate 10-day periods (month/01,month/11, month/21). For each date the long term minimum, maximum, mean, median and standard deviation are computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591f316-6817-4a2e-8f9a-7177c4824587",
   "metadata": {},
   "source": [
    "### S3-compatible Object Storage to access online data\n",
    "\n",
    "Up to now we have downloaded data locally and then opened with Xarray `open_dataset`. When willing to manipulate large amount of data, this approach is not optimal (since it requires a lot of unnecessary local downloads). Sharing data online as Object Storage allows for data sharing and access to much larger amounts of data.\n",
    "\n",
    "One of the most popular methods to access online remote data is through Amazon Simple Storage Service (S3) and you don't necessarily need to use Amazon services to benefit from S3 object storage. Many other providers offer S3-compatible object storage that can be accessed in a very similar way.\n",
    "\n",
    "Below we will be accessing online the NDVI Long Term Statistics from Copernicus Land Service that we have publicly stored in OpenStack Object storage (Swift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4fb7cf-cf82-47e4-8366-4f2dce155fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82f7f9-387f-4f25-b948-c6b4dcaed10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(anon=True,\n",
    "      client_kwargs={\n",
    "         'endpoint_url': 'https://object-store.cloud.muni.cz'\n",
    "      })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0405e6db-753f-4b8f-8135-237ff3f63fc2",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "The parameter `anon` is for `anonymous` and is set to `True` because the data we have stored at `https://object-store.cloud.muni.cz` is public\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea82d0e-ef18-456e-a65e-00dcb9f50a2e",
   "metadata": {},
   "source": [
    "#### List files and folders in existing buckets\n",
    "\n",
    "Instead of organizing files in various folders, object storage systems store files in a flat organization of containers (called \"buckets\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead3b51-aae8-4a8d-9188-df496d1f891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ls('foss4g-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efa44f-1dc5-4289-a78a-c5faae255186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs.ls('foss4g-data/CGLS_LTS_1999_2019_Lombardia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6851335f-8207-4860-870d-8cd31963d70b",
   "metadata": {},
   "source": [
    "#### Access remote files from S3-compatible Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe09d2-9fb2-456f-aac3-d6f38b1cf128",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3path = 's3://foss4g-data/CGLS_LTS_1999_2019_Lombardia/AOI_c_gls_NDVI-LTS_1999-2019-0101_GLOBE_VGT-PROBAV_V3.0.1.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029019e3-6e05-42f7-95d2-1218a45c8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS = xr.open_dataset(fs.open(s3path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62a7fe-bb13-421f-8003-23a7749fb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1214bb3-e404-4b73-be98-5c9d5072280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTS.sel(lat=45.88, lon=8.63, method='nearest')['min'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b20d20e-c88a-4825-bd70-a8e7d1eb72ef",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "The same dataset can be available from different locations e.g. [CGLS distributor VITO](https://vito.be/en), Zenodo, S3-compatible OpenStack Object storage (Swift), etc.\n",
    "How do you know if it corresponds to the very same dataset? You cannot know except if the datasets have a persistent identifier such as a Digital Object Identifier.\n",
    "It is therefore recommended *1)* to be extra careful about where you get your datasets, and *2)* to double check that the content is exactly what you expect (for instance, you can perform basic quality checks).                                                            \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d6ed7-e43c-4fec-8e34-caf8641948d0",
   "metadata": {},
   "source": [
    "#### Access multiple remote files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366d570-3f48-4e11-a647-5d7caf668276",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3path = 's3://foss4g-data/CGLS_LTS_1999_2019_Lombardia/AOI_c_gls_*.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085418aa-87ef-42c0-aacb-bbcd89543940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remote_files = fs.glob(s3path)\n",
    "remote_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8235a22-dfb4-442e-9c78-e450ccd32cce",
   "metadata": {},
   "source": [
    "We need to add a time dimension to concatenate data. For this, we define a function that will be called for each remote file (via the `preprocess` parameter of Xarray `open_mfdataset`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc368c-3aad-4bf8-b249-40768fc6c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128871ee-64ab-421a-bbcd-f9913ae54fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    t = datetime.strptime(ds.attrs['identifier'].split(':')[-1].split('_')[1].replace('1999-', ''), \"%Y-%m%d\")\n",
    "    return(ds.assign_coords(time=t).expand_dims('time'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb2bfc-a068-435a-80b7-bc50a7a8088a",
   "metadata": {},
   "source": [
    "Xarray `open_mfdataset` allows opening multiple files at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b6dd4-05c8-4c0e-8ca8-712665b0af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through remote_files to create a fileset\n",
    "fileset = [fs.open(file) for file in remote_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e55ec-488a-486c-8d15-83e040ad656b",
   "metadata": {},
   "source": [
    "When opening remote files, you can also select the variables you wish to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485973e-0972-4eba-85c0-50a68689c3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LTS = xr.open_mfdataset(fileset, combine='nested', concat_dim=['time'],  preprocess=preprocess,\n",
    "                        decode_coords=\"all\")\n",
    "LTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e4bbb-2965-462c-bfc7-d7f61531071f",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "If you use one of xarray’s open methods such as xarray.open_dataset to load netCDF files with the default engine, it is recommended to use decode_coords=”all”. This will load the grid mapping variable into coordinates for compatibility with rioxarray. See [rioxarray documentation](https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html#xarray).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc464ec7",
   "metadata": {},
   "source": [
    "## Preparing and discover online datasets\n",
    "\n",
    "With the plethora of cloud storage, there are many available online datasets. To ease the preparation and discovery of such datasets, we describe emerging community-driven initiatives promoting standards suited to both geospatial and geoscience communities. Most of the material below is adapted from a previous Pangeo 101 training {cite:ps}`galaxy2022-pangeo`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9f5bd",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "While we provide a general intro to some initiatives, we suggest below a list of FOSS4G 2022 talks with very interesting developments to prepare and discover spatio-temporal datasets in the cloud. Enjoy!\n",
    "\n",
    "- [STAC Best Practices and Tools](https://talks.osgeo.org/foss4g-2022/talk/9RRYZM/), 2022-08-24, 11:00–11:30\n",
    "- [Early use of FOSS4G in a space start up](https://talks.osgeo.org/foss4g-2022/talk/HG7RLR/), 2022-08-24, 11:30–12:00\n",
    "- [Exploring Data Interoperability with STAC and the Microsoft Planetary Computer](https://talks.osgeo.org/foss4g-2022/talk/L3KNY8/), 2022-08-24, 12:10–12:15\n",
    "- [Serving oblique aerial imagery using STAC and Cloud Optimized Geotiffs](https://talks.osgeo.org/foss4g-2022/talk/SQYE9A/), 2022-08-24, 14:45–15:15\n",
    "- [Pangeo Forge: Crowdsourcing Open Data in the Cloud](https://talks.osgeo.org/foss4g-2022/talk/DABTGG/). 2022-08-26, 10:00-10:30.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7daeb-be5e-4fc8-bee5-bd82a50fa57c",
   "metadata": {},
   "source": [
    "### Analysis Ready, cloud optimized data (ARCO)\n",
    "When analyzing data at scale, the data format used is key. For years, the main data format was netCDF e.g. Network Common Data Form but with the use of cloud computing and interest in Open Science, different formats are often more suitable.\n",
    "\n",
    "Formats for analyzing data from the cloud are refered to as \"Analysis Ready, Cloud Optimized\" data formats or in short ARCO. Find further info about ARCO datasets in {cite:ps}`Abernathey2022-arco`.\n",
    "\n",
    "What is \"Analysis Ready\"?\n",
    "* Think in terms of \"Datasets\" not \"data files\"\n",
    "* No need for tedious homogenizing / cleaning setup guides\n",
    "* Curated and cataloged\n",
    "\n",
    "What is \"Cloud Optimized\"?\n",
    "* Compatible with object storage e.g. access via HTTP\n",
    "* Supports lazy access and intelligent subsetting\n",
    "* Integrates with high-level analysis libraries and distributed frameworks\n",
    "\n",
    "Instead of having a big dataset, ARCO datasets are chunked appropriately for analysis and have rich metadata (See Figure 1).\n",
    "\n",
    "<img src=\"https://github.com/galaxyproject/training-material/blob/696dfecd4c88e59b487a7a3557cfedca6ec5754b/topics/climate/images/arco_data.png?raw=true\" align=\"Left\" /></a>\n",
    "\n",
    "*Fig 1. Example of an ARCO dataset. Source: {cite:ps}`galaxy2022-pangeo`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c8411a",
   "metadata": {},
   "source": [
    "### The Pangeo forge initiative\n",
    "\n",
    "[Pangeo Forge](https://pangeo-forge.org/) is an open source platform for data **Extraction**, **Transformation**, and **Loading** (ETL). The goal of *Pangeo Forge* is to make it easy to extract data from traditional repositories and deposit this data in cloud object storage in an analysis-ready, cloud optimized (ARCO) format {cite:ps}`galaxy2022-pangeo`.\n",
    "\n",
    "Pangeo Forge is inspired directly by Conda Forge, a community-led collection of recipes for building conda packages.\n",
    "\n",
    "It is under active development and the Pangeo community hopes it will play a role in democratizing the publication of datasets in ARCO format.\n",
    "\n",
    "#### How does Pangeo Forge work?\n",
    "\n",
    "Pangeo Forge defines the concept of a recipe, which specifies the logic for transforming a specific data archive into an ARCO data store.\n",
    "All contributions to Pangeo Forge must include an executable Python module, named recipe.py or similar, in which the data transformation logic is embedded (Figure 2).\n",
    "The recipe contributor is expected to use one of a predefined set of template algorithms defined by Pangeo Forge.\n",
    "Each of these templated algorithms is designed to transform data of a particular source type into a corresponding ARCO format, and requires only that the contributor populate the template with information unique to their specific data transformation, including the location of the source files and the way in which they should be aligned in the resulting ARCO data store {cite:ps}`Abernathey2022-arco`.\n",
    "\n",
    "The diagram below looks complicated but like for conda forge most of the process is automated.\n",
    "\n",
    "<img src=\"https://www.frontiersin.org/files/Articles/782909/fclim-03-782909-HTML/image_m/fclim-03-782909-g002.jpg\" align=\"Left\" /></a>\n",
    "\n",
    "*Fig 2. A recipe in relation to Pangeo Forge architecture. Source: {cite:ps}`Abernathey2022-arco`.*\n",
    "\n",
    "The next step after preparing the dataset is then to tell the community where and how to access to your transformed dataset.\n",
    "\n",
    "This is done by creating a catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469aa6f",
   "metadata": {},
   "source": [
    "### Spatio Temporal Asset Catalogs (STAC)\n",
    "\n",
    "The [STAC](https://stacspec.org/en/) specification is a common language to describe geospatial information, so it can more easily be worked with, indexed, and discovered.\n",
    "\n",
    "#### Why STAC?\n",
    "* Each provider has its own catalog and interface (APIs).\n",
    "* Every time you want to access a new catalog, you need to change your program.\n",
    "* We have lots of data providers and each with a bespoke interface.\n",
    "* It is becoming quickly difficult for programmers who need to design a new data connector each time.\n",
    "\n",
    "#### Features\n",
    "- STAC catalogs are extremely simple.\n",
    "- They are composed of three layers:\n",
    "    - **Catalogs**\n",
    "        - **Collections**\n",
    "            - **Items**\n",
    "- STAC is very popular for Earth Observation satellite imagery.\n",
    "- For instance it can be used to access Sentinel-2 in AWS (see Figure 3).\n",
    "\n",
    "<img src=\"https://github.com/galaxyproject/training-material/blob/696dfecd4c88e59b487a7a3557cfedca6ec5754b/topics/climate/images/sentinel2_AWS.png?raw=true\" align=\"Left\" /></a>\n",
    "\n",
    "*Fig 3. Example of STAC collection of Sentinel-2 images hosted in AWS.\n",
    "Source: {cite:ps}`galaxy2022-pangeo`.*\n",
    "\n",
    "\n",
    "#### STAC and Pangeo Forge\n",
    "- Pangeo-forge supports the creation of analysis-ready cloud optimized (ARCO) data in cloud object storage from \"classical\" data repositories.\n",
    "- STAC is used to create catalogs and goes beyond the Pangeo ecosystem.\n",
    "- Work is ongoing to figure out the best way to expose Pangeo-Forge-generated data assets via STAC catalogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531077be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ":::{tip}\n",
    "Pangeo members, Scott Henderson (University of Washington) and Tom Augspurger (Microsoft), provided a great workshop in FOSS4G 2021 covering STAC.\n",
    "\n",
    "Feel free to explore the GitHub repository of the  [here](https://github.com/pangeo-data/foss4g-2021).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17df17e-70c7-4120-823d-2df7c535f874",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <i class=\"fa-check-circle fa\" style=\"font-size: 22px;color:#666;\"></i> <b>Key Points</b>\n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>Access to remote dataset</li>\n",
    "        <li>ARCO datasets</li>\n",
    "        <li>Pangeo Forge</li>\n",
    "        <li>STAC</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77853a3",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":style: alpha\n",
    ":filter: topic % \"data-access\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c0b22",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Packages citation\n",
    "\n",
    "```{bibliography}\n",
    ":style: alpha\n",
    ":filter: topic % \"access\" and topic % \"package\"\n",
    ":keyprefix: c-\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
